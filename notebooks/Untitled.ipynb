{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685f170a-4f13-4063-b6d1-84a358ed2ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 18:18:11.985975: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b5a980-85df-48bf-a813-f5e5459b576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yahoo_finance_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81dc641-e6e3-4c6d-9a08-e59e75161321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Drop any missing values\n",
    "    data.dropna(inplace=True)\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb6dc8a-3a5c-4185-bf55-8ed178a47a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size):\n",
    "    train = data[:train_size]\n",
    "    test = data[train_size:]\n",
    "    print(\"Start\")\n",
    "    print(train)\n",
    "    print(\"end\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fd841fd-078e-497f-b6bf-2130b94553cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arima_model(train):\n",
    "    history = [x for x in train]\n",
    "    predictions = []\n",
    "    for t in range(len(train)):\n",
    "        model = ARIMA(history, order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a59643-764e-4f27-a416-203f2a3d705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann_model(train, test):\n",
    "    X_train, y_train = train[:, :-1], train[:, -1]\n",
    "    X_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd17c241-f8b9-4dca-8246-f0495598f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(train, test):\n",
    "    arima_predictions = train_arima_model(train)\n",
    "    ann_predictions = create_ann_model(train, test)\n",
    "\n",
    "    combined_predictions = (np.array(arima_predictions) + np.array(ann_predictions)) / 2\n",
    "\n",
    "    return combined_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65c34f23-cc21-4e3e-9c59-3ac32b339d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "[[0.21029244 0.22071883 0.25428793 0.23567731 0.23102334 0.23376706]\n",
      " [0.21310006 0.22065754 0.2583218  0.22661991 0.22208209 0.26231331]\n",
      " [0.20273357 0.21875956 0.24677445 0.23397124 0.22933937 0.18876348]\n",
      " ...\n",
      " [0.76144636 0.78460788 0.80058512 0.80173079 0.80001564 0.17341932]\n",
      " [0.79303957 0.78889375 0.8087144  0.78076237 0.77917349 0.18088235]\n",
      " [0.77674931 0.77505668 0.7699154  0.74304416 0.74168228 0.19469289]]\n",
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SARIMAX models require univariate `endog`. Got shape (202, 6).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoot Mean Squared Error (RMSE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split(scaled_data, train_size)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions using ARIMA-ANN hybrid model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m hybrid_model(train_data, test_data)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Invert predictions\u001b[39;00m\n\u001b[1;32m     19\u001b[0m predictions \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mconcatenate((train_data, predictions), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mhybrid_model\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhybrid_model\u001b[39m(train, test):\n\u001b[0;32m----> 2\u001b[0m     arima_predictions \u001b[38;5;241m=\u001b[39m train_arima_model(train)\n\u001b[1;32m      3\u001b[0m     ann_predictions \u001b[38;5;241m=\u001b[39m create_ann_model(train, test)\n\u001b[1;32m      5\u001b[0m     combined_predictions \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marray(arima_predictions) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ann_predictions)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m, in \u001b[0;36mtrain_arima_model\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train)):\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m ARIMA(history, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      7\u001b[0m     output \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mforecast()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/statsmodels/tsa/arima/model.py:158\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    151\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the specification\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# (don't pass specific values of enforce stationarity/invertibility,\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# because we don't actually want to restrict the estimators based on\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# this criteria. Instead, we'll just make sure that the parameter\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# estimates from those methods satisfy the criteria.)\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima \u001b[38;5;241m=\u001b[39m SARIMAXSpecification(\n\u001b[1;32m    159\u001b[0m     endog, exog\u001b[38;5;241m=\u001b[39mexog, order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[1;32m    160\u001b[0m     trend\u001b[38;5;241m=\u001b[39mtrend, enforce_stationarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enforce_invertibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m     concentrate_scale\u001b[38;5;241m=\u001b[39mconcentrate_scale, trend_offset\u001b[38;5;241m=\u001b[39mtrend_offset,\n\u001b[1;32m    162\u001b[0m     dates\u001b[38;5;241m=\u001b[39mdates, freq\u001b[38;5;241m=\u001b[39mfreq, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[1;32m    163\u001b[0m     validate_specification\u001b[38;5;241m=\u001b[39mvalidate_specification)\n\u001b[1;32m    164\u001b[0m exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39morig_exog\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Raise an error if we have a constant in an integrated model\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.11/site-packages/statsmodels/tsa/arima/specification.py:454\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Validate endog shape\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (validate_specification \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m faux_endog \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSARIMAX models require univariate `endog`. Got\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    455\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_missing \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)))\n",
      "\u001b[0;31mValueError\u001b[0m: SARIMAX models require univariate `endog`. Got shape (202, 6)."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Get data from Yahoo Finance\n",
    "    ticker = 'AAPL'  # Example: Apple Inc.\n",
    "    start_date = '2020-01-01'\n",
    "    end_date = '2021-01-01'\n",
    "    data = get_yahoo_finance_data(ticker, start_date, end_date)\n",
    "\n",
    "    # Preprocess data\n",
    "    scaled_data, scaler = preprocess_data(data)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    train_size = int(len(scaled_data) * 0.8)\n",
    "    train_data, test_data = train_test_split(scaled_data, train_size)\n",
    "\n",
    "    # Make predictions using ARIMA-ANN hybrid model\n",
    "    predictions = hybrid_model(train_data, test_data)\n",
    "\n",
    "    # Invert predictions\n",
    "    predictions = scaler.inverse_transform(np.concatenate((train_data, predictions), axis=1))[:, -1]\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_actual = scaler.inverse_transform(test_data)[:, -1]\n",
    "    rmse = np.sqrt(mean_squared_error(test_actual, predictions))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b66a23-a7cf-4e2e-afa9-7843cbe2cb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
